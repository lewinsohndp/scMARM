{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "import utilities\n",
    "import torch\n",
    "from label_sharpen_arm import LabelSharpen\n",
    "from label_prop_arm import LabelProp\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for i in np.arange(.1,.5,.1):\n",
    "    i = round(i, 5)\n",
    "    file_path = \"simulations/splat_\" + str(i) + \"_de/\"\n",
    "    temp_data = pd.read_csv(file_path + \"counts.csv\", index_col=0)\n",
    "    temp_meta = pd.read_csv(file_path + \"meta.csv\", index_col=0)\n",
    "    temp_preds = pd.read_csv(file_path + \"predictions.csv\", index_col=0)\n",
    "    temp_X = np.array(temp_data)\n",
    "    temp_y = pd.factorize(temp_meta['Group'], sort=True)[0]\n",
    "\n",
    "    temp = temp_preds.apply(pd.factorize, axis=0, sort=True)\n",
    "    temp = temp.iloc[0,:]\n",
    "    indices = list(temp.index)\n",
    "    d = {key: None for key in indices}\n",
    "    for i in range(temp.shape[0]):\n",
    "        d[indices[i]] = temp.iloc[i]\n",
    "\n",
    "    temp_preds = pd.DataFrame(d)\n",
    "    #temp_preds.apply(pd.factorize(), axis=0)\n",
    "    #temp_preds = pd.factorize(temp_preds, sort=True)[0]\n",
    "    datasets.append((temp_X, temp_y, temp_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_encoding(row):\n",
    "    change = np.random.normal(.5, .2)\n",
    "    if change < 0: change = 0\n",
    "    all_indices = list(range(len(row)))\n",
    "    max_index = np.argmax(row)\n",
    "    all_indices.pop(max_index)\n",
    "    row[max_index] = 1 - change\n",
    "    selections = random.sample(all_indices, 2)\n",
    "\n",
    "    for i in selections:\n",
    "        row[i] = change/2\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(dataset):\n",
    "    features = dataset[0]\n",
    "    labels = dataset[1]\n",
    "    preds = dataset[2]\n",
    "\n",
    "    all_preds = []\n",
    "    for i in range(preds.shape[1]):\n",
    "        all_preds.append(preds.iloc[:,i].to_numpy())\n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "    \n",
    "    #add -1 then remove so encoder takes into account unknowns even if there isn't any\n",
    "    all_preds = np.append(all_preds, -1)\n",
    "    enc = OneHotEncoder(drop='first')\n",
    "    encoded_y = enc.fit_transform(all_preds.reshape(-1,1)).toarray()\n",
    "    encoded_y = encoded_y[:-1,:]\n",
    "    # need to add three scores together\n",
    "    final_encoded = np.zeros(shape=(preds.shape[0],encoded_y.shape[1]))\n",
    "    scoring_length = preds.shape[0]\n",
    "    lower =0\n",
    "    upper = scoring_length\n",
    "    for i in range(int(len(encoded_y)/preds.shape[0])):\n",
    "        final_encoded += encoded_y[lower:upper,:]\n",
    "        lower = upper\n",
    "        upper += scoring_length\n",
    "\n",
    "    # turn encoded into prob. by dividng each row by it's sum\n",
    "    final_encoded = final_encoded / final_encoded.sum(axis=1, keepdims=True)\n",
    "    \"\"\"enc = OneHotEncoder()\n",
    "    encoded_y = enc.fit_transform(labels.reshape(-1,1)).toarray()\n",
    "    encoded_y = np.apply_along_axis(randomize_encoding, 1, encoded_y)\"\"\"\n",
    "\n",
    "    features = utilities.preprocess(features, scale=False)\n",
    "\n",
    "    return final_encoded, features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep 0.4 simulated training and validation sets\n",
    "encoded_y_one, features_one, y_one = prep_data(datasets[0])\n",
    "train_features = features_one[:800,:]\n",
    "#train_X = features[:10,:]\n",
    "train_X = encoded_y_one[:800,:]\n",
    "train_y = y_one[:800]\n",
    "\n",
    "test_features = features_one[800:,:]\n",
    "test_X = encoded_y_one[800:,:]\n",
    "test_y = y_one[800:]\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_features), torch.tensor(train_X),torch.tensor(train_y))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=35, shuffle=True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_features), torch.tensor(test_X),torch.tensor(test_y))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=35, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep test 0.3\n",
    "\n",
    "encoded_y_three, features_three, y_three = prep_data(datasets[2])\n",
    "\n",
    "test_dataset_three = torch.utils.data.TensorDataset(torch.tensor(features_three), torch.tensor(encoded_y_three),torch.tensor(y_three))\n",
    "test_dataloader_three = torch.utils.data.DataLoader(test_dataset_three, batch_size=35, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep test 0.2\n",
    "\n",
    "encoded_y_two, features_two, y_two = prep_data(datasets[1])\n",
    "\n",
    "test_dataset_two = torch.utils.data.TensorDataset(torch.tensor(features_two), torch.tensor(encoded_y_two),torch.tensor(y_two))\n",
    "test_dataloader_two = torch.utils.data.DataLoader(test_dataset_two, batch_size=35, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep test 0.1\n",
    "\n",
    "encoded_y_one, features_one, y_one = prep_data(datasets[0])\n",
    "\n",
    "test_dataset_one = torch.utils.data.TensorDataset(torch.tensor(features_one), torch.tensor(encoded_y_one),torch.tensor(y_one))\n",
    "test_dataloader_one = torch.utils.data.DataLoader(test_dataset_one, batch_size=35, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm = LabelSharpen(\"configs/sharpen_basic.txt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 28.803392\n",
      "Loss in epoch 10 = 13.313494\n",
      "Loss in epoch 20 = 11.186023\n",
      "Loss in epoch 30 = 10.507597\n",
      "Loss in epoch 40 = 10.075891\n",
      "Loss in epoch 50 = 9.643491\n",
      "Loss in epoch 60 = 9.346367\n",
      "Loss in epoch 70 = 8.955503\n",
      "Loss in epoch 80 = 8.736804\n",
      "Loss in epoch 90 = 8.839277\n"
     ]
    }
   ],
   "source": [
    "arm.train(train_dataloader,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9049999713897705,\n",
       " array([[329,  10,   2,   5],\n",
       "        [ 11, 150,  10,   2],\n",
       "        [  7,   9, 157,   4],\n",
       "        [  5,   7,   4,  88]]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm.validation_metrics(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9150)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(datasets[0][2]['SCINA'].to_numpy()[800:]) == torch.tensor(test_y)).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8925)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = torch.tensor(train_X).max(dim=1)[1]\n",
    "equality = torch.tensor(train_y) == final_pred\n",
    "equality.type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8899999856948853,\n",
       " array([[82,  1,  1,  1],\n",
       "        [ 6, 40,  3,  1],\n",
       "        [ 3,  0, 36,  3],\n",
       "        [ 2,  1,  0, 20]]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm.validation_metrics(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8900)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = torch.tensor(test_X).max(dim=1)[1]\n",
    "equality = torch.tensor(test_y) == final_pred\n",
    "equality.type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " array([[431,   0,   0,   0],\n",
       "        [  0, 223,   0,   0],\n",
       "        [  0,   0, 219,   0],\n",
       "        [  0,   0,   0, 127]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm.validation_metrics(test_dataloader_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = torch.tensor(encoded_y_three).max(dim=1)[1]\n",
    "equality = torch.tensor(y_three) == final_pred\n",
    "equality.type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9959999918937683,\n",
       " array([[428,   3,   0,   0],\n",
       "        [  0, 223,   0,   0],\n",
       "        [  1,   0, 218,   0],\n",
       "        [  0,   0,   0, 127]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm.validation_metrics(test_dataloader_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9980)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = torch.tensor(encoded_y_two).max(dim=1)[1]\n",
    "equality = torch.tensor(y_two) == final_pred\n",
    "equality.type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8090000152587891,\n",
       " array([[380,   8,  16,  27],\n",
       "        [ 70, 120,  16,  17],\n",
       "        [ 11,   4, 202,   2],\n",
       "        [  6,   3,  11, 107]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm.validation_metrics(test_dataloader_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8920)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = torch.tensor(encoded_y_one).max(dim=1)[1]\n",
    "equality = torch.tensor(y_one) == final_pred\n",
    "equality.type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_test(dataset):\n",
    "    features = dataset[0]\n",
    "    labels = dataset[1]\n",
    "    preds = dataset[2]\n",
    "\n",
    "    all_preds = []\n",
    "    for i in range(preds.shape[1]):\n",
    "        all_preds.append(preds.iloc[:,i].to_numpy())\n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "    \n",
    "    #add -1 then remove so encoder takes into account unknowns even if there isn't any\n",
    "    all_preds = np.append(all_preds, -1)\n",
    "    enc = OneHotEncoder(drop='first')\n",
    "    encoded_y = enc.fit_transform(all_preds.reshape(-1,1)).toarray()\n",
    "    encoded_y = encoded_y[:-1,:]\n",
    "    # need to add three scores together\n",
    "    final_encoded = np.zeros(shape=(preds.shape[0],encoded_y.shape[1]))\n",
    "    scoring_length = preds.shape[0]\n",
    "    lower =0\n",
    "    upper = scoring_length\n",
    "    for i in range(int(len(encoded_y)/preds.shape[0])):\n",
    "        final_encoded += encoded_y[lower:upper,:]\n",
    "        lower = upper\n",
    "        upper += scoring_length\n",
    "\n",
    "    # turn encoded into prob. by dividng each row by it's sum\n",
    "    #final_encoded = final_encoded / final_encoded.sum(axis=1, keepdims=True)\n",
    "    \"\"\"enc = OneHotEncoder()\n",
    "    encoded_y = enc.fit_transform(labels.reshape(-1,1)).toarray()\n",
    "    encoded_y = np.apply_along_axis(randomize_encoding, 1, encoded_y)\"\"\"\n",
    "\n",
    "    features = utilities.preprocess(features, scale=False)\n",
    "\n",
    "    return final_encoded, features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_y_one, features_one, y_one = prep_data_test(datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0., 0., 1.],\n",
       "       [0., 0., 2., 0.],\n",
       "       [1., 0., 2., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 2., 0., 0.],\n",
       "       [3., 0., 0., 0.],\n",
       "       [0., 2., 0., 0.],\n",
       "       [0., 0., 2., 0.],\n",
       "       [0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y_one[1:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "confident_labels = np.zeros(shape = (encoded_y_one.shape[0],))\n",
    "for i in range(encoded_y_one.shape[0]):\n",
    "    row = encoded_y_one[i,:]\n",
    "    max_index = np.argmax(row)\n",
    "    if row[max_index] > 1:\n",
    "        confident_labels[i] = max_index\n",
    "    else: confident_labels[i] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788\n",
      "840\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(len(confident_labels)):\n",
    "    if confident_labels[i] == -1: continue\n",
    "    if confident_labels[i] == y_one[i]: correct +=1\n",
    "    total += 1\n",
    "\n",
    "print(correct)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nodes = np.where(confident_labels == -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_arm = LabelProp(\"configs/semi_basic_linear.txt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_dataset  = torch.utils.data.TensorDataset(torch.tensor(features_one), torch.tensor(confident_labels))\n",
    "prop_dataloader = torch.utils.data.DataLoader(prop_dataset, batch_size=35, shuffle=True)\n",
    "\n",
    "prop_test_dataset  = torch.utils.data.TensorDataset(torch.tensor(features_one), torch.tensor(y_one))\n",
    "prop_test_dataloader = torch.utils.data.DataLoader(prop_test_dataset, batch_size=35, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 38.440067\n",
      "Loss in epoch 10 = 3.111017\n",
      "Loss in epoch 20 = 0.272159\n",
      "Loss in epoch 30 = 0.074041\n",
      "Loss in epoch 40 = 0.031537\n",
      "Loss in epoch 50 = 0.020813\n",
      "Loss in epoch 60 = 0.011673\n",
      "Loss in epoch 70 = 0.009322\n",
      "Loss in epoch 80 = 0.004970\n",
      "Loss in epoch 90 = 0.004087\n"
     ]
    }
   ],
   "source": [
    "prop_arm.train(prop_dataloader, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9129999876022339,\n",
       " array([[398,  13,  13,   7],\n",
       "        [ 11, 200,   8,   4],\n",
       "        [  6,   8, 204,   1],\n",
       "        [  6,   5,   5, 111]]),\n",
       " 0.78125,\n",
       " array([[68,  3, 10,  3],\n",
       "        [ 2, 27,  4,  2],\n",
       "        [ 4,  2, 21,  1],\n",
       "        [ 1,  1,  2,  9]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_arm.validation_metrics(prop_test_dataloader, test_nodes=test_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confident labels: 788/840\n",
    "Unconfident labels: 125/160\n",
    "Total: 913/1000 = 91.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7890)\n",
      "tensor(0.9230)\n",
      "tensor(0.0630)\n"
     ]
    }
   ],
   "source": [
    "id = 0\n",
    "print((torch.tensor(datasets[id][2]['scSorter']) == torch.tensor(y_one)).type(torch.FloatTensor).mean())\n",
    "print((torch.tensor(datasets[id][2]['SCINA']) == torch.tensor(y_one)).type(torch.FloatTensor).mean())\n",
    "print((torch.tensor(datasets[id][2]['scType']) == torch.tensor(y_one)).type(torch.FloatTensor).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1063)\n",
      "tensor(0.8438)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print((torch.tensor(datasets[id][2]['scSorter'])[test_nodes] == torch.tensor(y_one[test_nodes])).type(torch.FloatTensor).mean())\n",
    "print((torch.tensor(datasets[id][2]['SCINA'])[test_nodes] == torch.tensor(y_one[test_nodes])).type(torch.FloatTensor).mean())\n",
    "print((torch.tensor(datasets[id][2]['scType'])[test_nodes] == torch.tensor(y_one[test_nodes])).type(torch.FloatTensor).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e461d02738fd757bc3d2933f9434d370f54d79aa7bbf71ca755487c9a10e111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
